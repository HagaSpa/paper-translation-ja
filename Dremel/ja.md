# Dremel: Web規模における対話型分析

## 要約
Dremelはネストした読み取り用データに対して、スケーラブルでインタラクティブな、分析用クエリをアドホックに実行するシステムです。
マルチレベルの実行ツリーと列指向データレイアウトを組み合わせることにより、1兆を超える行数を持つテーブルに対して、すぐに集約クエリを実行することができます。
このシステムは数千を超えるCPUと、ペタバイトサイズのデータにスケールし、またgoogleには数千人のユーザがいます。
この論文では、Dremelのアーキテクチャおよび実装を描画し、またDremelがMapReduceベースのコンピューティングをどのように補完するかを説明します。
私たちはネストしたレコードのための新しい列指向の表現について提示し、システムの数千ノードにおける実験について説明します。

## 1. イントロダクション
大規模なデータ分析処理はweb企業や産業界に広まっています。
それは特にビジネスにおける、膨大な量の重要データを集めることが可能な低価格なストレージが要因となっています。
このようなデータをアナリストやエンジニアの手に置くことはますます重要になっています。
インタラクティブな処理のレスポンスにかかる時間は、しばしば定性的な違いが生まれます。
データ探索、モニタリング、オンラインの顧客サポート、高速なプロトタイプ開発、データパイプラインのデバックなどタスクによります。

インタラクティブなデータの分析処理は、大規模で高度な並列処理が必要です。
例えば1テラバイトの圧縮データを1秒で取得することは、今日におけるディスクでは何万台ものハードウェアが必要です。
同様にしてCPUを集中的に使うクエリを数秒で完了するために、千を超えるコアで実行する必要があります。
Googleでは、共有されている汎用機のクラスタを使用して巨大な並列処理を実行しています。
通常クラスタは、多種多様なワークロードを持ち、また複数の異なるハードウェアパラメータを持つ、機器上で動作する多数の分散型アプリケーションをホストしています。
分散型アプリケーションの一部のワーカーは、与えられたタスクの実行に要する時間が、他のワーカーよりも長くなるかもしれません。
または障害やクラスタのマネージメントシステムによる、事前準備処理のせいで完了できないかもしれません。
高速に処理を実行することや耐障害性を高めるためには、失敗したワーカーや障害に対する対処が必須です。

webと計算機科学の世界で使われているデータの多くは、リレーショナルなものではありません。
したがって、それらのドメインでは変更容易なデータモデルが重要です。
プログラム言語で使われているデータ構造は、分散システムによるメッセージ交換、構造化されたドキュメントなどなどです。
これらのデータ構造はネストされた、表現に対して有効です。
Web規模でそのようなデータの正規化や再結合をすることは、通常は禁止されています。
ネストされたデータモデルは、Googleや他のメジャーなWeb企業の報告によると、ほとんどの構造化されたデータ処理の基礎となります。

この論文では汎用クラスタによって共有された、とても巨大なデータセットに対する対話型分析処理をサポートする、Dremelと呼ばれるシステムについて説明します。
従来のデータベースとは異なり、それは「in situ」でネストされたデータに対して操作をすることができます。
「In situ」とは「所定の場所」でデータにアクセスする機能のことで、
例えばGFSのような分散ファイルシステムだったり、BigTableのような他のストレージシステムが含まれます。
Dremelは通常MapReduce処理のジョブが必要なデータに対して、わずかな時間でたくさんのクエリを実行することができます
DremelはMapReduceの代替品としては意図されておらず、またMapReduceのパイプラインの出力を分析したり、大規模な計算処理を迅速にプロトタイプ化するためによく使われています

Dremelは2006年から稼働しており、Google内部で数千人の利用者がいます。
GoogleにてデプロイされたDremelの複数のインスタンスは、数十から数千のノードに及びます。
例えば以下のようなシステムで使われています:
- クロールして取得したWebドキュメントの分析
- Android市場における、アプリケーションのインストールデータの追跡
- Google製品の障害報告
- Google Bookからの光学文字認識の結果
- スパムの分析
- Google Mapのデバック
- 管理されたBigTableのTabletの移行
- Googleの分散システム上でのテスト実行の結果
- 数千のディスクにおけるI/O情報の統計
- Googleのデータセンタ内のリソース管理のジョブ実行
- Googleのコードベースのシンボルと依存関係

DremelはWeb検索や並列DBMSから着想を得ています。
まず第一に、Dremelのアーキテクチャは分散型検索エンジンで使われている、サービングツリーのコンセプトを受けています。
ちょうどWeb検索のリクエストのように、クエリはツリーにプッシュされ、それぞれのステップで書き換えられます。
クエリの実行結果は低レベルのツリーから受け取ったレスポンスを集約することで、組み立てられています
次にDremelはアドホックなクエリを表現するために、高レベルなSQL言語に似た言語を提供します。
PigやHiveのようなレイヤとは対照的に、DremelはクエリをMapReduceのジョブに変換せずに、ネイティブ（生）な状態でクエリを実行します。

最後に重要なことですが、Dremelは列指向ストレージ表現を使います。
そのためセカンダリのストレージからより少ないのデータ量を読み取り、簡素な圧縮を行うことでCPUコストを削減できます
列指向のデータストアは、リレーショナルなデータに対する分析のために採用されましたが、
我々の知る限りそれはネストされたデータモデルのために拡張されていません。
私たちが推すカラム指向ストレージのフォーマットは、MapReduceやSawzallやFlumeJavaなどにも含まれています。

この論文では私たちは以下の内容について貢献します:
- ネストされたデータのための、新しい列指向ストレージ形式を紹介します。
ネストされたレコードを列単位で分解し、再度組み立て直すアルゴリズムも提示します。(セクション4)
- Dremelのクエリ言語と実行の概要について説明します。
どちらについても列が多いネストされたデータを効率的に処理するように設計されており、データをレコード形式に再構築することを必要としません。(セクション5)
- Web検索システムで使用されている実行木をデータベース処理に適用する方法と、集計クエリを効率的に実行できる利点について説明します。(セクション6)
- 1兆のレコードやマルチテラバイトのデータセットに対して、1000~4000ノードのインスタンス上で行われた実験について説明します。(セクション7)

この論文の構成は次の通りです。
セクション2では、Dremelと他のデータマネジメントツールをどのように組み合わせて使用するかを説明します。
データモデルについての説明はセクション3で行います。
セクション4~8では、上記で述べられている主な貢献について説明します。
関連する作業についてセクション9で議論します。
セクション10は結論です。


## 2.背景
まず初めに対話式のクエリ処理が、広範なデータ管理エコシステムにどのように適合するかを示すシナリオを説明します。
アリスはGoogleで働くエンジニアで、Webページから新しい種類のパラメータを抜き出す、斬新なアイデアを思いついた場合を例にします。
入力データを処理して、新しいパラメータを含むデータセットを作成するMapReduceのジョブを実行し、
分散システム上のファイルシステムに数十億のレコードとして格納しました。
実験の結果を分析するために、Dremelを起動し以下のコマンドを実行します:

```
DEFINE TABLE t AS /path/to/data/*
SELECT TOP(signal1, 100), COUNT(*) FROM t
```

彼女のコマンドは数秒で実行されます
彼女はアルゴリズムが動くことを確信するために、他のクエリをいくつか実行させます。
彼女は出力されたデータセットに対して、複雑な分析の計算を実行するためのFlumeJavaで書かれたプログラムでsignal1の不規則性を探します。
問題を修正したのち、彼女は入力データを継続して処理するパイプラインを設定します。
彼女はパイプラインの結果を様々なディメンションに集約する、いくつかのSQLクエリをテンプレート化し、それを対話型ダッシュボードに実装します。
最後に彼女はカタログ内の新しいデータセットを更新し、それから他のエンジニアが探索し、クエリを実行できるようにします。

上記のシナリオにはSQLクエリを実行するプロセッサと、他のデータマネジメントツール間での相互運用が要求されます。
そのための最初の案としては、共通のストレージ層があります。
Google File System(GFS)は、そのような分散型ストレージ層の一つで会社で広く利用されています。
GFSはレプリケーションを使って障害のあるハードウェアにもかかわらずデータを保存し、ストラグラーが存在する場合の応答時間を短縮します。
高パショーマンスのストレージ層はin situ（その場）なデータマネジメントでは重要です。
時間がかかるロードフェーズを省略してアクセスすることができ, 多くのMapReduceジョブを実行できる分析データ処理でのデータベース使用に対する主なインピーダンス[とある作業に対する比？]です。
（MapRedueジョブの中でも主な比率としてはロードフェーズがあると言いたい？）
DBMSがデータをロードして単一のクエリを実行する前に分析をします。
さらに追加の利点として、 ファイルシステム内のデータが基本的なツールによって利用しやすくなります。
例えば他のクラスターに転送したり、アクセス権を変更したり、分析のためにファイル名に基づいてサブセットを識別したりなど色々あります。

カラム志向のストレージはリレーショナルなデータに対しては成功することを証明したが、Googleではネストされたデータに適合させるのことが不可欠でした。
図1のイラストの主な内容: ネストされたA, B, Cという値が連続して格納されています。
したがって、A,B,CはA->EやA->B->Dなどは、読込みなしで目的のデータを取得できます。
私たちが対処するチャレンジは構造化されたデータを保存しあるフィールドの集合から、レコードの再構築を可能にするものです
次章では私たちのデータモデルから、アルゴリズムとクエリ処理について説明します。


## 3.データモデル
この章ではDremelのデータモデルの説明と、後ほど使用される単語について紹介します.
このデータモデルは分散システム用の用途に最適化されたデータモデルで、（[Protocol Buffers](https://ja.wikipedia.org/wiki/Protocol_Buffers)と呼ばれます）Googleで広く使われている、またossとして利用可能な実装です。
Protocol Buffersは強い型付をされた、ネストされたレコードをベースとしてます。抽象化した構文は以下です。

``` 
τ = dom | hA1 : τ [∗|?], . . . , An : τ [∗|?]i
```
τ はアトミックなDOMか、レコードの型です。
DOMの型は整数、浮動小数点数、文字列などです。
レコードは１つもしくは複数のフィールドで構成されます。
レコードにあるiのというフィールドは、名前A[i]とオプショナルな複数のラベルがあります。
繰り返しフィールド(*)は、１つのレコード内で複数回出現する可能性があります。
それらはリストとして解釈されます。つまりフィールドがレコードに発生した順番が重要です。
オプショナルなフィールド(?) は出現しない可能性があります。
それ以外の場合は、フィールドは必須です。つまり最低でも1回は出現する必要があります。

図の2について考えてみましょう。
この図はWebドキュメントのレコードを定義したスキーマについて描いています。
スキーマ定義は次のシンタックスを使用します。[21]
このドキュメントは必須な整数型のDocIdとオプショナルなLinksで構成されており、LinksはForwardまたはBackwardにある他のWebページのDocIDを含んだリストを持っています。
またドキュメントは複数のNameを持っており、それらはドキュメントを参照可能な異なるURLです。
Nameは連続したCodeと、オプショナルなCountryを含みます。
図の2では2つのサンプルレコードを表示しており、r1とr2は共にスキーマ定義に適合しています。
これらの例を使用して、次の章ではアルゴリズムの解説を行います。
スキーマに定義されたフィールドは、木構造に変換されます。
ネストしたフィールドのフルパスはドット(.)を使った繋ぎで示されています。例) Name.Language.Code.

ネストされたデータモデルはプラットフォームに依存せず、Googleで構造化データをシリアライズするための拡張可能なメカニズムです。
コード生成ツールはC++やJavaのようなプログラム言語のバインディングを生成します。
言語間の相互運用性はレコードのバイナリを通して達成され、フィールドはレコード内で現れた順番通りにレイアウトされます。
このようにJavaで実装されたMapReduceのプログラムは、C++のライブラリ経由でデータソースのレコードを解釈できます。
したがってもしレコードが列形式で保存されてる場合、それらを迅速にアセンブリすることは、MapReduceとその他データ処理ツールによる相互運用のために重要です。


## 4. ネストされた列指向ストレージ
図の1に示すように、私たちのゴールはあるフィールドの全ての値を連続して格納することで、検索の効率を上げて行くことです。
この章では、次の課題に対処します。列形式を損失なくレコード構造に表現し直す方法（セクション4.1）迅速なエンコーディング(セクション4.2)、また効率的なレコードの組み立て（セクション4.3）

### 4.1 繰り返しと定義のレベル
一つの値だけではレコードの構造を伝えることはできません。
二つの連続したフィールドが与えられても、それがどの程度繰り返されているかわかりません。
（例えば異なる2つのレコードからの値なのか、もしくは同じレコードにある連続した2つの値なのかなど。）
同様に, オプショナルなフィールドが欠落した状態で与えられた場合、どのレコードに定義されたものなのかわかりません。
したがってこれから繰り返しと定義のレベルについて、以下に定義されたコンセプトを紹介します。
例えば図の3を見ると、サンプルのレコードにある単純なフィールド（=ネストしていない）の、繰り返しと定義のレベルについて要約してます。

「Repetition levels」について。図の2にあるCodeについて考えて見ましょう。それはr1というレコードに3回現れています。
'en-us'と'en'の発生している場所は最初のNameの中にあり、'en-gb'は3番目のNameにあります。
それらの発生を明確にするために、「Repetition levels」をそれぞれの値に付与します。
それはパスとして表現されたフィールドの、どこで値が繰り返されたかを私たちに教えてくれます。 
フィールドであるName.Language.Codeは2つのリピートされるフィールドを含んでおり、NameとLanguageです。
したがって、Codeの「Repetition level」の範囲は0~2です。レベル0は新しいレコードの開始を示しています。
ここでは、レコードr1を上からスキャンすることにします。
'en-us'に遭遇した時、そのパス（Name.Language.Code）はそのレコードの中で初めて出現したフィールドです。この場合「Repetition level」は0です。
'en'はLanguageから繰り返されており、Languageは上から2つめの階層の要素のため、「Repetition level」は2です。
最後は'en-gb'ですが、Nameから繰り返されています。Nameはルート（1つ目の階層）にあるため、「Repetition level」は1です。
したがってr1レコードの「Repetition level」は、0,2,1となります。
